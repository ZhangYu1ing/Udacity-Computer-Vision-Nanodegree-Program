{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2> Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Uploading Caption File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'/home/tarushi/Desktop/Img-Caption/dataset/annotations_trainval2014/annotations/captions_train2014.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(path)\n",
    "data=json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Extracting Captions**\n",
    "We'll now extract the captions of the images. Each Image has been provided with five captions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be extracting the captions for the images I have. \n",
    "So that I don't encounter an 'image not found' error,I'll list out the images stored in my system and match their names with the image ids of the annotation provided to get captions for those particular images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COCO_train2014_000000105728.jpg',\n",
       " 'COCO_train2014_000000175053.jpg',\n",
       " 'COCO_train2014_000000047249.jpg',\n",
       " 'COCO_train2014_000000264241.jpg',\n",
       " 'COCO_train2014_000000162693.jpg',\n",
       " 'COCO_train2014_000000204785.jpg',\n",
       " 'COCO_train2014_000000203976.jpg',\n",
       " 'COCO_train2014_000000223461.jpg',\n",
       " 'COCO_train2014_000000057300.jpg',\n",
       " 'COCO_train2014_000000147250.jpg']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_imgs=r'/home/tarushi/Desktop/Img-Caption/images/train2014'\n",
    "img_list=os.listdir(path_imgs)\n",
    "img_list=img_list[:3000]\n",
    "img_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_captions=[]\n",
    "for i in data['annotations']:\n",
    "    img_id='COCO_train2014_' + '%012d.jpg' % (i['image_id'])\n",
    "    if img_id in img_list:\n",
    "        all_captions.append(['<start>'+i['caption']+'<end>',img_id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next,I'll sort out the obtained captions according to the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<start>a man and woman cut into a big cake <end>',\n",
       "  'COCO_train2014_000000000113.jpg'],\n",
       " ['<start>A man and woman standing in front of a cake.<end>',\n",
       "  'COCO_train2014_000000000113.jpg']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_captions= sorted(all_captions,key=lambda x:x[1])\n",
    "all_captions[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>a man and woman cut into a big cake <end>',\n",
       " '<start>A man and woman standing in front of a cake.<end>']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_captions=[all_captions[i][0] for i in range(len(all_captions))]\n",
    "sorted_captions[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15002"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h2>Preprocessing and Tokenizing the Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h3>Tokenizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the top 5000 words from the vocabulary\n",
    "top_k = 5000\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n",
    "                                                  oov_token=\"<unk>\",\n",
    "                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(all_captions)\n",
    "train_seqs = tokenizer.texts_to_sequences(all_captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h3>Padding the Sequences**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tokenized vectors\n",
    "train_seqs = tokenizer.texts_to_sequences(all_captions)\n",
    "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')\n",
    "max_length = calc_max_length(train_seqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "print(max_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
